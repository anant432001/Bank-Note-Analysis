# -*- coding: utf-8 -*-
"""Bank_note_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ehcOFab9CMCPnj79ZZY2uRHC7KLfQxho

In this project, we will classify a banknote as fake or genuine based on the given dataset from UCI machine learning repository which consists of about 1372 rows with 5 columns.

We will be using different algorithms such as **Logistic Regression, Support Vector Machine, RandomForestClassifier, KNeighborsClassifier, Multilayer Perceptron.**

##**Importing required libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pprint

# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

"""##**Reading Dataset**

**Data Set Information:**

-> Data were extracted from images that were taken from genuine and forged banknote-like specimens.<br>
-> For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels.<br>
-> Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained.<br>-> Wavelet Transform tool were used to extract features from images.
"""

df = pd.read_csv('BankNote_Authentication.csv')

print('Shape of the dataset = ',df.shape, '\n')
df.head()

df.columns

"""**Attribute Information:**

1 - variance of Wavelet Transformed image (continuous)

2 - skewness of Wavelet Transformed image (continuous)

3 - curtosis of Wavelet Transformed image (continuous)

4 - entropy of image (continuous)

5 - class (integer) -----> **Target Feature**
"""

df.dtypes

df['class'].value_counts()

"""0 -> Fake Note<br>
1 -> Real Note
"""

df.isna().sum()

"""There is no NULL value in our dataset, it is ready to use.<br>
Let's Proceed

##**Data Visualization**
"""

df.describe().T

"""**Correlation**"""

df.corr()

"""**Correlation - HeatMap**"""

plt.figure(figsize = (16, 9))

sns.heatmap(df.corr(), annot = True, linewidths = 2, )
plt.show()

"""**Univariate Data Analysis**"""

sns.distplot(df['class'])

plt.title('Distribution of "Class" attribute', fontsize = 14)
plt.show()

"""**Multi-variate Data Analysis**"""

df.hist(bins = 20, layout = (3,2), figsize = (16, 9), )
plt.show()

"""**PairPlot with hue = 'class'**"""

sns.pairplot(df, hue = 'class')

plt.show()

"""##**Model Building**

#####**Data Preparation**
"""

X_data = df.drop(columns = 'class', axis = 1)
y_data = df['class']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state = 1, test_size = 0.3)

print(X_train.shape, '\n')
X_train.head()

"""#####**Feature Scaling**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler() #Will also convert pandas dataframe to numpy array

X_train = scaler.fit_transform(X_train) 
X_test = scaler.fit_transform(X_test)

acc_score = {} #Dictionary to store accuracu score of different algorithms

"""**Importing some common libraries**"""

from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score

"""#####**Model - 1: Logistic Regression**"""

from sklearn.linear_model import LogisticRegression

LR_classifier = LogisticRegression(solver = 'liblinear', random_state = 1) #liblinear is a good choice for small dataset
LR_classifier.fit(X_train, y_train)

accuracies = cross_val_score(estimator = LR_classifier, X = X_train, y = y_train, cv = 10)
print('Accuracies:\n', accuracies, '\n')
print('Mean of Accuracies = ', accuracies.mean())

LR_y_pred = LR_classifier.predict(X_test) #Predicting on the data

ac = accuracy_score(y_test, LR_y_pred)

acc_score['Logistic Regression'] = ac #Appending into the dictionary
print('\nAccuracy = ',ac)

"""**Confusion Matrix for Logistic Regression**"""

from sklearn import metrics

cm = metrics.confusion_matrix(y_test, LR_y_pred, labels = [0,1])

df_cm = pd.DataFrame(cm, index = [i for i in [0,1]], columns = [i for i in ["Predict 0","Predict 1"]])

plt.figure(figsize = (10,7))
sns.heatmap(df_cm, annot = True, linewidths = 2)

plt.title('Logistic Regression Classifier HeatMap', fontsize = 14)
plt.show()



"""#####**Model - 2: Support Vector Machine**"""

from sklearn.svm import SVC

SVM_classifier = SVC()
SVM_classifier.fit(X_train, y_train)

accuracies = cross_val_score(estimator = SVM_classifier, X = X_train, y = y_train, cv = 10)
print('Accuracies:\n', accuracies, '\n')
print('Mean of Accuracies = ', accuracies.mean())

SVM_y_pred = SVM_classifier.predict(X_test)

ac = accuracy_score(y_test, SVM_y_pred)

acc_score['SVM']  = ac
print('\nAccuracy = ',ac)

"""**Confusion Matrix for SVM**"""

from sklearn import metrics

cm = metrics.confusion_matrix(y_test, SVM_y_pred, labels = [0,1])

df_cm = pd.DataFrame(cm, index = [i for i in [0,1]], columns = [i for i in ["Predict 0","Predict 1"]])

plt.figure(figsize = (10,7))
sns.heatmap(df_cm, annot = True, linewidths = 2)

plt.title('SVM Classifier HeatMap', fontsize = 14)
plt.show()

"""#####**Model - 2.1: Support Vector Machine**
Kernels in SVM classification refer to the function that is responsible for defining the decision boundaries between the classes.<br><br>
Apart from the classic linear kernel which assumes that the different classes are separated by a straight line, a RBF (radial basis function) kernel is used when the boundaries are hypothesized to be curve-shaped.<br><br>
RBF kernel uses two main parameters, gamma and C that are related to:
<br>1 - the decision region (how spread the region is), and
<br>2 - the penalty for misclassifying a data point<br>
respectively
"""

from sklearn.svm import SVC

SVM_rbf_classifier = SVC(kernel= 'rbf')
SVM_rbf_classifier.fit(X_train, y_train)

accuracies = cross_val_score(estimator = SVM_rbf_classifier, X = X_train, y = y_train, cv = 10)
print('Accuracies:\n', accuracies, '\n')
print('Mean of Accuracies = ', accuracies.mean())

SVM_rbf_y_pred = SVM_rbf_classifier.predict(X_test)

ac = accuracy_score(y_test, SVM_rbf_y_pred)

acc_score['SVM_rbf'] = ac
print('\nAccuracy = ',ac)

"""**Confusion Matrix for SVM (rbf)**"""

from sklearn import metrics

cm = metrics.confusion_matrix(y_test, SVM_rbf_y_pred, labels = [0,1])

df_cm = pd.DataFrame(cm, index = [i for i in [0,1]], columns = [i for i in ["Predict 0","Predict 1"]])

plt.figure(figsize = (10,7))
sns.heatmap(df_cm, annot = True, linewidths = 2)

plt.title('SVM(rbf) Classifier HeatMap', fontsize = 14)
plt.show()

"""#####**Model - 3: Random Forest Classifier**"""

from sklearn.ensemble import RandomForestClassifier

RF_classifier = RandomForestClassifier(n_estimators=50, criterion='entropy', random_state=0)
RF_classifier.fit(X_train, y_train)

accuracies = cross_val_score(estimator = RF_classifier, X = X_train, y = y_train, cv = 10)
print('Accuracies:\n', accuracies, '\n')
print('Mean of Accuracies = ', accuracies.mean())

RF_y_pred = RF_classifier.predict(X_test)

ac = accuracy_score(y_test, RF_y_pred)

acc_score['Random Forest'] = ac
print('\nAccuracy = ', ac)

"""**Confusion Matrix for Random Forest Classifier**"""

from sklearn import metrics

cm = metrics.confusion_matrix(y_test, RF_y_pred, labels = [0,1])

df_cm = pd.DataFrame(cm, index = [i for i in [0,1]], columns = [i for i in ["Predict 0","Predict 1"]])

plt.figure(figsize = (10,7))
sns.heatmap(df_cm, annot = True, linewidths = 2)

plt.title('Random Forest Classifier HeatMap', fontsize = 14)
plt.show()

"""#####**Model - 4: KNN Classifier**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import KFold, GridSearchCV

param_grid = {'leaf_size': [2, 5, 7, 9, 11],
              'n_neighbors': [2, 5, 7, 9, 11],
              'p': [1, 2]}
grid = GridSearchCV(KNeighborsClassifier(), param_grid = param_grid)
grid.fit(X_train, y_train)

grid.best_params_

final_KNN_Model = grid.best_estimator_

KNN = KNeighborsClassifier(n_neighbors=2, p=2, leaf_size=2)

KNN.fit(X_train, y_train)

KNN_y_pred = KNN.predict(X_test)

ac = accuracy_score(y_test,KNN_y_pred)

acc_score['KNN'] = ac
print(ac)

"""**Confusion Matrix for KNN Classifier**"""

from sklearn import metrics

cm = metrics.confusion_matrix(y_test, KNN_y_pred, labels = [0,1])

df_cm = pd.DataFrame(cm, index = [i for i in [0,1]], columns = [i for i in ["Predict 0","Predict 1"]])

plt.figure(figsize = (10,7))
sns.heatmap(df_cm, annot = True, linewidths = 2)

plt.title('KNN Classifier HeatMap', fontsize = 14)
plt.show()

"""#####**Model - 5: Multilayer Perceptron**"""

from sklearn.neural_network import MLPClassifier

multi_classifier = MLPClassifier(hidden_layer_sizes = (8,4), max_iter = 8000, alpha = 0.0001, solver='sgd', verbose=10,
                                 random_state=21, tol=0.000000001)

multi_classifier.fit(X_train,y_train)

accuracies = cross_val_score(estimator = multi_classifier, X = X_test, y = y_test, cv = 10)
print(accuracies)

print('Mean of Accuracies = ', accuracies.mean())

multi_y_pred = multi_classifier.predict(X_test)

ac = accuracy_score(y_test,multi_y_pred)

acc_score['MLP'] = ac
print(ac)

"""**Confusion Matrix for MLP Classifier**"""

from sklearn import metrics

cm = metrics.confusion_matrix(y_test, multi_y_pred, labels = [0,1])

df_cm = pd.DataFrame(cm, index = [i for i in [0,1]], columns = [i for i in ["Predict 0","Predict 1"]])

plt.figure(figsize = (10,7))
sns.heatmap(df_cm, annot = True, linewidths = 2)

plt.title('MLP Classifier HeatMap', fontsize = 14)
plt.show()

"""#####**Accuracy score of Algorithms**"""

print('Accuracy Score for different Algorithms:\n')
for key, value in acc_score.items():
  print(key, ' = ', value*100, '\n')

